"""
Gemini AI Service for Exam PDF Answer Extraction
=================================================
Uses Gemini AI to intelligently extract answer keys from Vietnamese exam PDFs.
Supports MC (tráº¯c nghiá»‡m), TF (Ä‘Ãºng/sai), and SA (tráº£ lá»i ngáº¯n) questions.
"""

import os
import logging
import httpx
import asyncio
import json
import re
from typing import Optional, Dict, Any, List

# ============================================================================
# LOGGING
# ============================================================================

logger = logging.getLogger("gemini_service")

# ============================================================================
# CONFIGURATION
# ============================================================================

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "sk-ewNhLj4fTcPUGWDstbRMibwnhjtZ5gB4q4CxMhEQ0gg5xZlx")
GEMINI_BASE_URL = os.getenv("GEMINI_BASE_URL", "https://v98store.com")

# Models to try
MODELS = [
    "gemini-2.0-flash",        # Fallback - fast + cheap
    "gemini-3-flash-preview",  # Try first - more capable
]

# ============================================================================
# ANSWER EXTRACTION PROMPT (User's improved version)
# ============================================================================

EXTRACTION_PROMPT = """# VAI TRÃ’
Báº¡n lÃ  má»™t trá»£ lÃ½ AI chuyÃªn xá»­ lÃ½ vÃ  trÃ­ch xuáº¥t dá»¯ liá»‡u tá»« cÃ¡c tÃ i liá»‡u giÃ¡o dá»¥c. Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  Ä‘á»‹nh vá»‹ chÃ­nh xÃ¡c pháº§n "ÄÃP ÃN" hoáº·c "HÆ¯á»šNG DáºªN CHáº¤M" (thÆ°á»ng náº±m á»Ÿ cuá»‘i tÃ i liá»‡u) vÃ  trÃ­ch xuáº¥t thÃ´ng tin Ä‘Ã³ ra má»™t Ä‘á»‹nh dáº¡ng cÃ³ cáº¥u trÃºc.

# NHIá»†M Vá»¤ Cá»¤ THá»‚
1. **QuÃ©t tÃ i liá»‡u:** Bá» qua ná»™i dung cÃ¡c cÃ¢u há»i Ä‘á» bÃ i. HÃ£y tÃ¬m cÃ¡c tá»« khÃ³a bÃ¡o hiá»‡u pháº§n Ä‘Ã¡p Ã¡n nhÆ°: "ÄÃP ÃN", "Báº¢NG ÄÃP ÃN", "HÆ¯á»šNG DáºªN CHáº¤M", hoáº·c cÃ¡c báº£ng biá»ƒu náº±m á»Ÿ trang cuá»‘i cÃ¹ng.
2. **Nháº­n diá»‡n Ä‘á»‹nh dáº¡ng:** Äá» thi cÃ³ thá»ƒ bao gá»“m má»™t hoáº·c káº¿t há»£p cÃ¡c pháº§n sau:
   - **Pháº§n 1 (Tráº¯c nghiá»‡m 4 lá»±a chá»n):** ThÆ°á»ng cÃ³ dáº¡ng 1.A, 2.B...
   - **Pháº§n 2 (ÄÃºng/Sai):** ThÆ°á»ng cÃ³ dáº¡ng CÃ¢u 1: a) Ä, b) S, c) Ä, d) S...
   - **Pháº§n 3 (Tráº£ lá»i ngáº¯n):** ThÆ°á»ng cÃ³ dáº¡ng CÃ¢u 1: 5.6, CÃ¢u 2: -10...
3. **TrÃ­ch xuáº¥t & Chuáº©n hÃ³a:** Chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u tÃ¬m Ä‘Æ°á»£c thÃ nh Ä‘á»‹nh dáº¡ng JSON.

# QUY Táº®C Xá»¬ LÃ
- Náº¿u Ä‘Ã¡p Ã¡n náº±m trong báº£ng káº» Ã´, hÃ£y Ä‘á»c theo tá»«ng hÃ ng/cá»™t tÆ°Æ¡ng á»©ng.
- Náº¿u Ä‘Ã¡p Ã¡n viáº¿t liá»n (VD: 1A 2B 3C), hÃ£y tÃ¡ch riÃªng tá»«ng cÃ¢u.
- Vá»›i dáº¡ng ÄÃºng/Sai: Pháº£i ghi rÃµ tá»«ng Ã½ nhá» (a, b, c, d) lÃ  ÄÃºng hay Sai.
- Loáº¡i bá» cÃ¡c kÃ½ tá»± thá»«a, chá»‰ giá»¯ láº¡i sá»‘ thá»© tá»± cÃ¢u vÃ  giÃ¡ trá»‹ Ä‘Ã¡p Ã¡n.
- **QUAN TRá»ŒNG:** Náº¿u Ä‘á» chá»‰ cÃ³ tráº¯c nghiá»‡m thuáº§n (30-40 cÃ¢u A/B/C/D), thÃ¬ phan_dung_sai vÃ  phan_tra_loi_ngan pháº£i lÃ  máº£ng rá»—ng [].

# Äá»ŠNH Dáº NG Äáº¦U RA (JSON - khÃ´ng markdown, khÃ´ng giáº£i thÃ­ch)
{{
  "phan_trac_nghiem": [
    {{"cau": 1, "dap_an": "A"}},
    {{"cau": 2, "dap_an": "C"}}
  ],
  "phan_dung_sai": [
    {{
      "cau": 13,
      "y_a": "ÄÃºng",
      "y_b": "Sai",
      "y_c": "ÄÃºng",
      "y_d": "Sai"
    }}
  ],
  "phan_tra_loi_ngan": [
    {{"cau": 17, "dap_an": "2024"}},
    {{"cau": 18, "dap_an": "4.5"}}
  ]
}}

# VÄ‚N Báº¢N Cáº¦N Xá»¬ LÃ
{text}
"""


# ============================================================================
# GEMINI CLIENT
# ============================================================================

class GeminiClient:
    """Gemini AI client for answer extraction."""
    
    def __init__(self, api_key: str = None, base_url: str = None, timeout: float = 60.0):
        self.api_key = api_key or GEMINI_API_KEY
        self.base_url = (base_url or GEMINI_BASE_URL).rstrip('/')
        self.timeout = timeout
        logger.info(f"GeminiClient initialized with base URL: {self.base_url}")
    
    async def extract_answers(self, pdf_text: str) -> Dict[str, Any]:
        """
        Use AI to extract answers from PDF text.
        
        Args:
            pdf_text: Extracted text from PDF
            
        Returns:
            Dict with multiple_choice, true_false, short_answer arrays
        """
        prompt = EXTRACTION_PROMPT.format(text=pdf_text[:15000])  # Limit text length
        
        for model in MODELS:
            logger.info(f"Trying model: {model}")
            result = await self._try_model(model, prompt)
            if result:
                return result
        
        logger.error("All AI models failed, returning empty result")
        return {
            "multiple_choice": [],
            "true_false": [],
            "short_answer": [],
            "error": "AI extraction failed - all models unavailable"
        }
    
    async def _try_model(self, model: str, prompt: str) -> Optional[Dict]:
        """Try a specific model."""
        try:
            url = f"{self.base_url}/v1/chat/completions"
            
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": model,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.1,  # Low temp for consistent extraction
                "max_tokens": 8192
            }
            
            async with httpx.AsyncClient(timeout=self.timeout) as client:
                response = await client.post(url, headers=headers, json=payload)
                
                if response.status_code == 200:
                    data = response.json()
                    text = data.get("choices", [{}])[0].get("message", {}).get("content", "")
                    
                    if text:
                        # Parse JSON from response
                        result = self._parse_json_response(text)
                        if result:
                            result["model"] = model
                            logger.info(f"Success with model: {model}")
                            return result
                
                logger.warning(f"Model {model} returned status {response.status_code}")
                
        except Exception as e:
            logger.error(f"Model {model} failed: {e}")
        
        return None
    
    def _parse_json_response(self, text: str) -> Optional[Dict]:
        """Parse JSON from AI response, handling potential markdown formatting."""
        try:
            # Remove markdown code blocks if present
            text = text.strip()
            if text.startswith("```json"):
                text = text[7:]
            elif text.startswith("```"):
                text = text[3:]
            if text.endswith("```"):
                text = text[:-3]
            text = text.strip()
            
            # Debug: print first part of response
            print(f"ðŸ” AI Raw Response (first 500 chars): {text[:500]}")
            
            # Try direct parsing first
            try:
                data = json.loads(text)
            except json.JSONDecodeError:
                # Try to fix common issues
                # 1. Truncated JSON - try to close brackets
                if text.count('{') > text.count('}'):
                    text += '}' * (text.count('{') - text.count('}'))
                if text.count('[') > text.count(']'):
                    text += ']' * (text.count('[') - text.count(']'))
                
                # 2. Try parsing again
                try:
                    data = json.loads(text)
                except json.JSONDecodeError:
                    # 3. Try to extract just the MC answers using regex
                    mc_match = re.search(r'"multiple_choice"\s*:\s*\[(.*?)\]', text, re.DOTALL)
                    if mc_match:
                        mc_str = mc_match.group(1)
                        # Extract individual answers
                        answers = re.findall(r'"([A-D])"', mc_str)
                        if answers:
                            print(f"âš¡ Fallback: Extracted {len(answers)} MC answers via regex")
                            return {
                                "multiple_choice": answers,
                                "true_false": [],
                                "short_answer": []
                            }
                    
                    # Try Vietnamese regex fallback
                    vn_match = re.search(r'"phan_trac_nghiem"\s*:\s*\[(.*?)\]', text, re.DOTALL)
                    if vn_match:
                        # Extract from Vietnamese format
                        answers = re.findall(r'"dap_an"\s*:\s*"([A-D])"', vn_match.group(1))
                        if answers:
                            print(f"âš¡ Fallback VN: Extracted {len(answers)} MC answers via regex")
                            return {
                                "multiple_choice": answers,
                                "true_false": [],
                                "short_answer": []
                            }
                    
                    print(f"âŒ Cannot parse JSON, raw text: {text[:1000]}")
                    return None
            
            # Handle Vietnamese format and convert to English
            if "phan_trac_nghiem" in data:
                # Convert from Vietnamese format
                mc_list = data.get("phan_trac_nghiem", [])
                multiple_choice = [item.get("dap_an", "").upper() for item in mc_list if isinstance(item, dict)]
                
                tf_list = data.get("phan_dung_sai", [])
                true_false = []
                for item in tf_list:
                    if isinstance(item, dict):
                        true_false.append({
                            "question": item.get("cau", 0),
                            "answers": {
                                "a": item.get("y_a", "").lower() == "Ä‘Ãºng",
                                "b": item.get("y_b", "").lower() == "Ä‘Ãºng",
                                "c": item.get("y_c", "").lower() == "Ä‘Ãºng",
                                "d": item.get("y_d", "").lower() == "Ä‘Ãºng"
                            }
                        })
                
                sa_list = data.get("phan_tra_loi_ngan", [])
                short_answer = []
                for item in sa_list:
                    if isinstance(item, dict):
                        short_answer.append({
                            "question": item.get("cau", 0),
                            "answer": str(item.get("dap_an", ""))
                        })
                
                result = {
                    "multiple_choice": multiple_choice,
                    "true_false": true_false,
                    "short_answer": short_answer
                }
            else:
                # Already in English format
                result = {
                    "multiple_choice": data.get("multiple_choice", []),
                    "true_false": data.get("true_false", []),
                    "short_answer": data.get("short_answer", [])
                }
            
            # Normalize MC answers to uppercase
            result["multiple_choice"] = [
                ans.upper() if isinstance(ans, str) else ans 
                for ans in result["multiple_choice"]
            ]
            
            return result
            
        except Exception as e:
            logger.error(f"JSON parse error: {e}")
            print(f"âŒ JSON parse exception: {e}")
            return None

# ============================================================================
# GLOBAL INSTANCE
# ============================================================================

gemini_client = GeminiClient()

# ============================================================================
# VISION PROMPT FOR IMAGE-BASED ANSWER KEYS (Vietnamese format)
# ============================================================================

VISION_PROMPT = """# VAI TRÃ’
Báº¡n lÃ  AI trÃ­ch xuáº¥t Ä‘Ã¡p Ã¡n tá»« áº£nh báº£ng Ä‘Ã¡p Ã¡n Ä‘á» thi THPT Viá»‡t Nam.

# NHIá»†M Vá»¤
Äá»c báº£ng Ä‘Ã¡p Ã¡n trong áº£nh vÃ  trÃ­ch xuáº¥t:
- **Pháº§n 1 (Tráº¯c nghiá»‡m):** ÄÃ¡p Ã¡n A/B/C/D
- **Pháº§n 2 (ÄÃºng/Sai):** Má»—i Ã½ a,b,c,d lÃ  ÄÃºng hay Sai
- **Pháº§n 3 (Tráº£ lá»i ngáº¯n):** GiÃ¡ trá»‹ sá»‘ (giá»¯ nguyÃªn dáº¥u pháº©y)

# LÆ¯U Ã
- Náº¿u chá»‰ cÃ³ tráº¯c nghiá»‡m thuáº§n â†’ phan_dung_sai vÃ  phan_tra_loi_ngan lÃ  []
- Äá»c theo thá»© tá»± hÃ ng/cá»™t trong báº£ng

# OUTPUT JSON (khÃ´ng markdown)
{
  "phan_trac_nghiem": [
    {"cau": 1, "dap_an": "A"},
    {"cau": 2, "dap_an": "C"}
  ],
  "phan_dung_sai": [
    {"cau": 13, "y_a": "ÄÃºng", "y_b": "Sai", "y_c": "ÄÃºng", "y_d": "Sai"}
  ],
  "phan_tra_loi_ngan": [
    {"cau": 17, "dap_an": "2,5"}
  ]
}

CHá»ˆ TRáº¢ Vá»€ JSON."""


# ============================================================================
# VISION EXTRACTION FUNCTION
# ============================================================================

async def extract_answers_from_image(image_base64: str, mime_type: str = "image/png") -> Dict[str, Any]:
    """
    Extract answers from an image of answer key using Gemini Vision.
    
    Args:
        image_base64: Base64 encoded image data
        mime_type: MIME type of the image (image/png, image/jpeg)
        
    Returns:
        Dict with answer data
    """
    try:
        url = f"{gemini_client.base_url}/v1/chat/completions"
        
        headers = {
            "Authorization": f"Bearer {gemini_client.api_key}",
            "Content-Type": "application/json"
        }
        
        # Message with image for vision model
        payload = {
            "model": "gemini-2.0-flash",  # Vision capable
            "messages": [{
                "role": "user",
                "content": [
                    {"type": "text", "text": VISION_PROMPT},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:{mime_type};base64,{image_base64}"
                        }
                    }
                ]
            }],
            "temperature": 0.1,
            "max_tokens": 4096
        }
        
        print(f"ðŸ–¼ï¸ Sending image to Gemini Vision...")
        
        async with httpx.AsyncClient(timeout=90.0) as client:
            response = await client.post(url, headers=headers, json=payload)
            
            if response.status_code == 200:
                data = response.json()
                text = data.get("choices", [{}])[0].get("message", {}).get("content", "")
                
                print(f"ðŸ–¼ï¸ Vision response: {text[:500]}")
                
                if text:
                    result = gemini_client._parse_json_response(text)
                    if result:
                        result["model"] = "gemini-2.0-flash-vision"
                        result["extraction_method"] = "vision"
                        print(f"âœ… Vision extraction successful!")
                        return result
            else:
                print(f"âŒ Vision API error: {response.status_code}")
                print(f"Response: {response.text[:500]}")
                
    except Exception as e:
        print(f"âŒ Vision extraction error: {e}")
        import traceback
        print(traceback.format_exc())
    
    return {
        "multiple_choice": [],
        "true_false": [],
        "short_answer": [],
        "error": "Vision extraction failed"
    }

# ============================================================================
# CONVENIENCE FUNCTION
# ============================================================================

async def extract_answers_with_ai(pdf_text: str) -> Dict[str, Any]:
    """
    Main function to extract answers using AI (text mode).
    
    Args:
        pdf_text: Text extracted from PDF
        
    Returns:
        Dict with answer data
    """
    return await gemini_client.extract_answers(pdf_text)
